{
    "do_train":true,
    "do_eval":true,
    "per_device_train_batch_size":2 ,
    "per_device_eval_batch_size":2 ,
    "output_dir":"out/1234",
    "num_train_epochs": 6,
    "lr_scheduler_type": "cosine",
    "learning_rate" : 1e-4 ,
    "warmup_ratio": 0.1,
    "logging_steps": 10,
    "save_strategy": "steps",
    "save_steps": 10,
    "save_total_limit" : 2 ,
    "evaluation_strategy": "steps",
    "eval_steps": 10,
    "optim": "adamw_torch",
    "fp16": false,
    "remove_unused_columns": false,
    "ddp_find_unused_parameters": false,
    "seed": 52,
    "report_to":"tensorboard" ,
    "load_best_model_at_end":true,
    "overwrite_output_dir":true,
    "gradient_accumulation_steps": 1 ,
    "ddp_timeout" : 6000 ,
    "logging_first_step" : true ,
    "gradient_checkpointing" :  true ,
    "weight_decay" :1e-4 ,

    
 
    "qlora":true,
    "use_peft":true,
    "target_modules" :"all",
    "lora_rank" : 64 ,
    "lora_dropout" :0.05 ,
    "lora_alpha" : 16 ,
    "modules_to_save": null,
    "peft_path": null 
   
}
